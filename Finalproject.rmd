---
title: "Project Analysis"
author: "Sarah Zhao"
date: "June 2, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Coursera Practical Machine Learning Project

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 
##Data:

The training data for this project are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment. 

##Project procedures:

##Call libraries which will be used for the project:
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
```


##Getting the data:

Firstly, store the data only in memory and then to disk.
```{r}
UrlTrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(UrlTrain), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(UrlTest), na.strings=c("NA","#DIV/0!",""))

```

##Remove unwanted variables for both training and testing data:
Reduce the number of variables by removing columns that have near zero values, NA, or is empty.
Remove columns with Near Zero Values (0 or #DIV/0!)
```{r}
subTrain <- training[,names(training)[!(nzv(training,saveMetrics=T)[,4])]] 
```
Remove columns with NA or is empty
```{r}
subTrain <- subTrain[,names(subTrain)[sapply(subTrain,function(x)!(any(is.na(x)|x=="")))]]
```

Remove "X" column which is just an ID number and not a variable, and cvtd_timestamp which is not a variable will be taken into account in the prediction. 
```{r}
subTrain <- subTrain[,-1]
subTrain <- subTrain[,c(1:3,5:58)]

```

Do the same for testing data:
```{r}
testing <- testing[,names(testing)[!(nzv(testing,saveMetrics=T)[,4])]]
testing <- testing[,names(testing)[sapply(testing,function(x)!(any(is.na(x)|x=="")))]]
testing <- testing[,-1]
testing <- testing[,c(1:3,5:58)]
dim(subTrain)
dim(testing)

```

##Separate the data to be used for Cross Validation
```{r}
inTrain <- createDataPartition(subTrain$classe, p = 0.6, list = FALSE)
subTraining <- subTrain[inTrain,]
subValidation <- subTrain[-inTrain,]

```
At this step, SubTraining data set got 11,776 observations for 57 variables while subValidation got 7,846 observations for 57 variables.


##Modeling: 
##A.I will try Decision Tree for prediction:
```{r}
modFit <- rpart(classe ~., data=subTraining, method="class")
```
view the decision tree:
```{r}
fancyRpartPlot(modFit)
predictions <- predict(modFit,subValidation,type="class")
```
Confusion Matrix used to test results:
```{r}  
confusionMatrix(predictions,subValidation$classe)
```
Accuracy is not ideal,so another algorithm will be considered.

##B: Using Random Forests and cross validation:
Since Random Forests is one of the top two performing algorithms, I will try RF to improve the accuracy.

I will train the model using training data with PCA and 10 fold cross validation. Then tested it using validation data and generate a confusion matrix to call out the model accuracy.

```{r}
modFit2 <- train(subTraining$classe~., method = "rf", preProcess=c("pca"), trControl = trainControl(method = "cv", number=10), data=subTraining)
cm <- confusionMatrix(subValidation$classe, predict(modFit2, subValidation))
cm
```
##Error estimation
I got the prediction accuracy of 0.9767 and kappa of 0.9705. 
Out of sample error is 1-0.9767=0.0233

Random Forests generated better results, we will choose this model to predict test cases.



